{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d72e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X Post Generator Workflow - An Iterative Tweet Generation System\n",
    "\n",
    "This notebook demonstrates an iterative LangGraph workflow that:\n",
    "1. Generates original, humorous tweets on a given topic\n",
    "2. Evaluates tweets based on humor, originality, virality, and format\n",
    "3. Optimizes tweets through feedback loops until approved or max iterations reached\n",
    "4. Maintains history of all tweets and feedback for analysis\n",
    "\n",
    "The workflow uses three specialized LLMs:\n",
    "- Generator: Creates funny, viral-worthy tweets\n",
    "- Evaluator: Critiques tweets against quality criteria\n",
    "- Optimizer: Refines tweets based on feedback\n",
    "\n",
    "Perfect example of iterative AI workflows with conditional routing and state management.\n",
    "\"\"\"\n",
    "\n",
    "# Import necessary libraries and load environment variables\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import TypedDict, Literal, Annotated\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from dotenv import load_dotenv\n",
    "import operator\n",
    "\n",
    "load_dotenv(dotenv_path='../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609b721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator, evaluator, and optimizer LLMs\n",
    "generator_llm = ChatGroq(model=\"compound-beta-mini\")\n",
    "evaluator_llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "optimizer_llm = ChatGroq(model=\"meta-llama/llama-4-maverick-17b-128e-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fad66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tweet evaluation output schema using Pydantic\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal['approved', 'needs_improvement'] = Field(..., description='Final')\n",
    "    feedback : str = Field(..., description='feedback for the tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910b1e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare evaluator for structured TweetEvaluation output\n",
    "structured_evaluator_llm = evaluator_llm.with_structured_output(TweetEvaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b3001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the processing state schema for tweets\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TweetEvaluation(BaseModel):\n",
    "    evaluation: Literal['approved', 'needs_improvement'] = Field(..., description='Final')\n",
    "    feedback : str = Field(..., description='feedback for the tweet')\n",
    "\n",
    "class TweetState(TypedDict):\n",
    "    topic : str\n",
    "    tweet : str\n",
    "    evaluation : Literal['approved', 'needs_improvement']\n",
    "    feedback : str\n",
    "    iteration: int\n",
    "    max_iteration : int\n",
    "    \n",
    "    tweet_history: Annotated[list[str], operator.add]\n",
    "    feedback_history: Annotated[list[str], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new tweet based on the topic and return with history\n",
    "def generate_tweet(state : TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content='You are a funny and clever Twitter/X influencer'),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Write a short, original and hilarious tweet on the topic : {state['topic']}.\n",
    "        \n",
    "        Rules :\n",
    "        - Do NOT use question-answer format.\n",
    "        - Max 280 characters.\n",
    "        - Use Observational humor, irony , sarcasm or cultural references.\n",
    "        - Think in meme logic, punchlines or relatable takes.\n",
    "        - Use simple, day to day english.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = generator_llm.invoke(messages).content\n",
    "    return {'tweet' : response, 'tweet_history' : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b934b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the tweet and record feedback\n",
    "def evaluate_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content='You are a ruthless, no laugh-given Twitter critic. You evaluate tweets based on humor, originality , virality and tweet format.'),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Evaluate the follwing tweet:\n",
    "        Tweet : \"{state['tweet']}\"\n",
    "        \n",
    "        Use the criteria below to evaluate the tweet:\n",
    "        1. Originality - Is this fresh, or have you seen it a hundred times before?\n",
    "        2. Humor - Did it genuinely make you smile, laugh or chuckle?\n",
    "        3. Punchiness - is it short, sharp and scroll-stopping\n",
    "        4. Virality Potential - Would people retweet or share it?\n",
    "        5. Format - Is it a well-formed tweet (not a setup punchline joke, not a Q&A joke , and under 280 characters)?\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = structured_evaluator_llm.invoke(messages)\n",
    "    return {'evaluation' : response.evaluation, 'feedback': response.feedback, 'feedback_history' : [response.feedback]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240307b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refine the tweet based on feedback and increment iteration\n",
    "def optimize_tweet(state: TweetState):\n",
    "    messages = [\n",
    "        SystemMessage(content='You punch up tweets for virality and humor based on given feedback'),\n",
    "        HumanMessage(content=f\"\"\"\n",
    "        Improve the tweet based on this feedback:\n",
    "        \"{state['feedback']}\"\n",
    "        \n",
    "        Topic : \"{state['topic']}\"\n",
    "        Original Tweet: {state['tweet']}\n",
    "        \n",
    "        Rewrite it as a short , viral-worthy tweet. Avoid Q&A styles and stay under 280 characters.\n",
    "        \"\"\")\n",
    "    ]\n",
    "    \n",
    "    response = optimizer_llm.invoke(messages).content\n",
    "    iteration = state['iteration'] + 1\n",
    "    return {'tweet' : response, 'iteration': iteration, 'tweet_history' : [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a923bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether to stop or loop back based on evaluation and iteration\n",
    "def route_evaluation(state: TweetState):\n",
    "    if state['evaluation'] == 'approved' or state['iteration'] >= state['max_iteration']:\n",
    "        return 'approved'\n",
    "    else :\n",
    "        return 'needs_improvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the state graph with generate, evaluate, and optimize steps\n",
    "graph = StateGraph(TweetState)\n",
    "\n",
    "graph.add_node('generate', generate_tweet)\n",
    "graph.add_node('evaluate', evaluate_tweet)\n",
    "graph.add_node('optimize', optimize_tweet)\n",
    "\n",
    "graph.add_edge(START, 'generate')\n",
    "graph.add_edge('generate', 'evaluate')\n",
    "graph.add_conditional_edges('evaluate', route_evaluation, {'approved' : END, 'needs_improvement': 'optimize'})\n",
    "graph.add_edge('optimize', 'evaluate')\n",
    "\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04b0ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +-----------+             \n",
      "          | __start__ |             \n",
      "          +-----------+             \n",
      "                 *                  \n",
      "                 *                  \n",
      "                 *                  \n",
      "           +----------+             \n",
      "           | generate |             \n",
      "           +----------+             \n",
      "                 *                  \n",
      "                 *                  \n",
      "                 *                  \n",
      "           +----------+             \n",
      "           | evaluate |             \n",
      "           +----------+             \n",
      "          ...         **            \n",
      "         .              **          \n",
      "       ..                 *         \n",
      "+---------+           +----------+  \n",
      "| __end__ |           | optimize |  \n",
      "+---------+           +----------+  \n"
     ]
    }
   ],
   "source": [
    "# Display the workflow's ASCII diagram\n",
    "workflow.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0174b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Indian railways',\n",
       " 'tweet': '\"Just boarded the Indian Railways express... aka the world\\'s longest therapy session. 3 days, 10 delays, and 1 unbearable seatmate later, I\\'m basically a life coach #IndianRailways #TrainLife\"',\n",
       " 'evaluation': 'approved',\n",
       " 'feedback': \"This tweet is a great example of a well-crafted tweet that effectively balances originality, humor, and punchiness. The comparison of the Indian Railways express to 'the world's longest therapy session' is a fresh and humorous take on a common experience. The addition of specific details like '3 days, 10 delays, and 1 unbearable seatmate' adds to the comedic effect and makes the tweet more relatable. The use of hashtags #IndianRailways and #TrainLife also increases its virality potential. The tweet is well-formed, under 280 characters, and does not follow a traditional setup-punchline joke format, making it a strong contender for retweets and shares.\",\n",
       " 'iteration': 1,\n",
       " 'max_iteration': 5,\n",
       " 'tweet_history': ['\"Just boarded the Indian Railways express... aka the world\\'s longest therapy session. 3 days, 10 delays, and 1 unbearable seatmate later, I\\'m basically a life coach #IndianRailways #TrainLife\"'],\n",
       " 'feedback_history': [\"This tweet is a great example of a well-crafted tweet that effectively balances originality, humor, and punchiness. The comparison of the Indian Railways express to 'the world's longest therapy session' is a fresh and humorous take on a common experience. The addition of specific details like '3 days, 10 delays, and 1 unbearable seatmate' adds to the comedic effect and makes the tweet more relatable. The use of hashtags #IndianRailways and #TrainLife also increases its virality potential. The tweet is well-formed, under 280 characters, and does not follow a traditional setup-punchline joke format, making it a strong contender for retweets and shares.\"]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up initial state and run the workflow to get final result\n",
    "initial_state = {\n",
    "    'topic' : 'Indian railways',\n",
    "    'iteration' : 1,\n",
    "    'max_iteration' : 5\n",
    "}\n",
    "\n",
    "result = workflow.invoke(initial_state)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb21182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
