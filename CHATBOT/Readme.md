# ğŸ¤– LangGraph Chatbot

<div align="center">

![LangGraph](https://img.shields.io/badge/LangGraph-ğŸ¦œ-green?style=for-the-badge)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=Streamlit&logoColor=white)
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54)
![Groq](https://img.shields.io/badge/Groq-FF6B35?style=for-the-badge&logo=groq&logoColor=white)

**A production-ready chatbot built with LangGraph's state management and Streamlit's interactive UI**

[ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ—ï¸ Architecture](#%EF%B8%8F-architecture) â€¢ [ğŸ’¡ Features](#-features) â€¢ [ğŸ”§ Setup](#-setup)

</div>

---

## ğŸŒŸ Overview

This chatbot demonstrates the power of **LangGraph** for building stateful conversational AI applications. Built with modern tools like **Streamlit** for the frontend and **Groq's Llama 3.3** for lightning-fast inference, it showcases how to create production-ready chatbots with persistent conversation memory.

## âœ¨ Features

ğŸ”„ **Persistent Conversations** - Maintains chat history across interactions using LangGraph's checkpointing  
âš¡ **Lightning Fast** - Powered by Groq's optimized Llama 3.3-70B model  
ğŸ¨ **Beautiful UI** - Clean, intuitive Streamlit interface  
ğŸ§  **State Management** - Advanced state handling with LangGraph's StateGraph  
ğŸ’¾ **Memory Persistence** - In-memory conversation storage with InMemorySaver  
ğŸ”§ **Modular Design** - Separated backend logic and frontend presentation  

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[ğŸ‘¤ User Input] --> B[ğŸ–¥ï¸ Streamlit Frontend]
    B --> C[ğŸ¤– LangGraph Backend]
    C --> D[ğŸ§  Groq Llama 3.3]
    D --> E[ğŸ’¾ InMemorySaver]
    E --> F[ğŸ“ Response]
    F --> B
    B --> G[ğŸ’¬ Chat Display]
```

### ğŸ”§ Core Components

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Frontend** | User interface & chat display | Streamlit |
| **Backend** | State management & conversation flow | LangGraph |
| **LLM** | Natural language processing | Groq Llama 3.3-70B |
| **Memory** | Conversation persistence | InMemorySaver |
| **State** | Message history tracking | StateGraph |

## ğŸš€ Quick Start

### Prerequisites
- Python 3.8+
- Groq API Key
- Virtual environment (recommended)

### 1ï¸âƒ£ Clone & Navigate
```bash
cd CHATBOT
```

### 2ï¸âƒ£ Environment Setup
```bash
# Activate your virtual environment
# On Windows:
.\langgraph-env\Scripts\Activate.ps1

# Install dependencies (if not already installed)
pip install streamlit langgraph langchain-groq python-dotenv
```

### 3ï¸âƒ£ Configure Environment
Create a `.env` file in the parent directory with your Groq API key:
```env
GROQ_API_KEY=your_groq_api_key_here
```

### 4ï¸âƒ£ Launch the Chatbot
```bash
streamlit run streamlit_frontend.py
```

ğŸ‰ **That's it!** Your chatbot will open in your browser at `http://localhost:8501`

## ğŸ’¡ How It Works

### ğŸ”„ Conversation Flow

1. **User Input** â†’ User types a message in Streamlit interface
2. **State Update** â†’ Message added to conversation history
3. **LangGraph Processing** â†’ Backend processes message through StateGraph
4. **LLM Inference** â†’ Groq's Llama 3.3 generates response
5. **Memory Storage** â†’ Conversation saved with InMemorySaver
6. **UI Update** â†’ Response displayed in chat interface

### ğŸ§  State Management

```python
class ChatState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
```

The chatbot uses LangGraph's powerful state management to:
- âœ… Track conversation history
- âœ… Maintain context across messages
- âœ… Enable future enhancements (tools, memory, etc.)

## ğŸ”§ Customization

### ğŸ¨ Change the Model
Modify `langgraph_backend.py`:
```python
model = ChatGroq(model="mixtral-8x7b-32768")  # Different model
```

### ğŸ­ Add System Prompt
```python
def chat_node(state: ChatState) -> ChatState:
    system_message = SystemMessage(content="You are a helpful assistant...")
    messages = [system_message] + state['messages']
    response = model.invoke(messages)
    return {'messages': [response]}
```

### ğŸ¨ Customize UI
Edit `streamlit_frontend.py` to:
- Change page title: `st.set_page_config(page_title="My Chatbot")`
- Add sidebar: `st.sidebar.title("Chat Settings")`
- Modify styling with CSS

## ğŸ“ Project Structure

```
CHATBOT/
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ¤– langgraph_backend.py   # LangGraph state management
â”œâ”€â”€ ğŸ–¥ï¸ streamlit_frontend.py  # Streamlit UI
â””â”€â”€ ğŸ““ Chatbot_Workflow.ipynb # Development notebook
```

## ğŸ› ï¸ Advanced Features

### ğŸ”® Future Enhancements
- ğŸ”§ **Tool Integration** - Add web search, calculations, etc.
- ğŸ—ƒï¸ **Database Storage** - Replace InMemorySaver with persistent DB
- ğŸ‘¥ **Multi-user Support** - Individual conversation threads
- ğŸ¨ **Custom Themes** - Personalized UI styling
- ğŸ“Š **Analytics Dashboard** - Conversation insights

### ğŸ§ª Development Mode
Use the included Jupyter notebook for experimentation:
```bash
jupyter notebook Chatbot_Workflow.ipynb
```

## ğŸ¤ Contributing

Found a bug or want to add a feature? Contributions are welcome!

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

## ğŸ“ License

This project is part of the LangGraph Tutorials collection.

---

<div align="center">

**Built with â¤ï¸ using LangGraph and Streamlit**

â­ **Star this repo if you found it helpful!** â­

</div>
