{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e85f375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review Reply Conditional Workflow\n",
    "# This notebook demonstrates conditional branching in LangGraph for automated review response generation\n",
    "# The workflow detects sentiment, diagnoses issues, and generates appropriate replies\n",
    "\n",
    "# Import required modules\n",
    "from langchain_groq import ChatGroq                    # Groq LLM integration\n",
    "from langgraph.graph import StateGraph, START, END    # LangGraph workflow components\n",
    "from pydantic import BaseModel, Field                 # For structured output schema\n",
    "from typing import Literal, TypedDict                 # Type-safe state definition\n",
    "from dotenv import load_dotenv                        # Environment variable management\n",
    "\n",
    "# Load environment variables (API keys)\n",
    "load_dotenv(dotenv_path='../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d53a5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Large Language Model\n",
    "model = ChatGroq(model=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8f4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Sentiment Output Schema\n",
    "# Used for structured LLM output on sentiment detection\n",
    "class SentimentSchema(BaseModel):\n",
    "    sentiment: Literal['positive', 'negative'] = Field(description='Sentiment of the review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ec726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Diagnosis Output Schema\n",
    "# Used for structured LLM output on issue diagnosis\n",
    "class DiagnosisSchema(BaseModel):\n",
    "    issue_type : Literal['UX', 'Performance', 'Bug', 'Support', 'Other'] = Field(description='The category of issue mentioned in the review')\n",
    "    tone : Literal['angry', 'frustrated', 'disappointed', 'calm'] = Field(description='The emotional tone expressed by the user')\n",
    "    urgency : Literal['low', 'medium','high'] = Field(description='How urgent or critical the issue appears to be')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0e6eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the LLM for structured output\n",
    "structured_model = model.with_structured_output(SentimentSchema)\n",
    "structured_model2 = model.with_structured_output(DiagnosisSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e32e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Sentiment Detection Prompt\n",
    "prompt = 'What is the sentiment of the following review : The phone is super bad. It is outright trash. Total waste of money.'\n",
    "\n",
    "structured_model.invoke(prompt).sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c555e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Review State Schema\n",
    "# Tracks review text, sentiment, diagnosis, and generated response\n",
    "class ReviewState(TypedDict):\n",
    "    review : str\n",
    "    sentiment : Literal['positive', 'negative']\n",
    "    diagnosis : dict\n",
    "    response : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state: ReviewState): \n",
    "    \"\"\"\n",
    "    Step 1: Detect sentiment of the review using LLM\n",
    "    Updates state with detected sentiment\n",
    "    \"\"\"\n",
    "    prompt = f'For the following review find out the sentiment \\n {state[\"review\"]}'\n",
    "    sentiment = structured_model.invoke(prompt).sentiment\n",
    "    state['sentiment'] = sentiment\n",
    "    return state\n",
    "\n",
    "def check_sentiment(state: ReviewState) -> Literal['positive_response', 'run_diagnosis']:\n",
    "    \"\"\"\n",
    "    Step 2: Conditional branching based on sentiment\n",
    "    Returns next node name\n",
    "    \"\"\"\n",
    "    if state[\"sentiment\"] == 'positive':\n",
    "        return 'positive_response'\n",
    "    else :\n",
    "        return 'run_diagnosis'\n",
    "\n",
    "def positive_response(state: ReviewState):\n",
    "    \"\"\"\n",
    "    Step 3a: Generate a warm thank you message for positive reviews\n",
    "    Updates state with response\n",
    "    \"\"\"\n",
    "    prompt = f'Write a warm thank you message in reponse to this review\\n\\n {state[\"review\"]} \\n Also , kindly ask the user to leave a feedback on our website'\n",
    "    response = model.invoke(prompt).content\n",
    "    state['response'] = response\n",
    "    return state\n",
    "\n",
    "def run_diagnosis(state: ReviewState):\n",
    "    \"\"\"\n",
    "    Step 3b: Diagnose negative review for issue type, tone, and urgency\n",
    "    Updates state with diagnosis\n",
    "    \"\"\"\n",
    "    prompt = f\"Diagnose this negative review: \\n\\n {state['review']}\\n Return issue_type, tone and urgency.\"\n",
    "    response = structured_model2.invoke(prompt)\n",
    "    state['diagnosis'] = response.model_dump()\n",
    "    return state\n",
    "\n",
    "def negative_response(state: ReviewState):\n",
    "    \"\"\"\n",
    "    Step 3c: Generate empathetic resolution message for negative reviews\n",
    "    Updates state with response\n",
    "    \"\"\"\n",
    "    diagnosis = state[\"diagnosis\"]\n",
    "    prompt = f\"You are a support assistant. The user has a '{diagnosis['issue_type']}' issue, sounded '{diagnosis['tone']}' , and marked urgency as '{diagnosis['urgency']}'. Write an empathetic, helpful resolution message\"\n",
    "    response = model.invoke(prompt).content\n",
    "    state['response'] = response\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8585d204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Conditional Review Reply Workflow Graph\n",
    "# The workflow branches based on sentiment and generates appropriate responses\n",
    "\n",
    "graph = StateGraph(ReviewState)\n",
    "\n",
    "# Add nodes for each step\n",
    "graph.add_node('find_sentiment', find_sentiment)              # Detect sentiment\n",
    "graph.add_node('positive_response', positive_response)        # Generate thank you for positive reviews\n",
    "graph.add_node('run_diagnosis', run_diagnosis)                # Diagnose negative reviews\n",
    "graph.add_node('negative_response', negative_response)        # Generate resolution for negative reviews\n",
    "\n",
    "# Define edges for sequential and conditional flow\n",
    "graph.add_edge(START, 'find_sentiment')\n",
    "graph.add_conditional_edges('find_sentiment', check_sentiment)\n",
    "graph.add_edge('positive_response', END)\n",
    "graph.add_edge('run_diagnosis', 'negative_response')\n",
    "graph.add_edge('negative_response', END)\n",
    "\n",
    "# Compile the graph into an executable workflow\n",
    "workflow = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7678871f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    +-----------+                      \n",
      "                    | __start__ |                      \n",
      "                    +-----------+                      \n",
      "                          *                            \n",
      "                          *                            \n",
      "                          *                            \n",
      "                  +----------------+                   \n",
      "                  | find_sentiment |                   \n",
      "                  +----------------+                   \n",
      "                  ..             ...                   \n",
      "               ...                  ...                \n",
      "             ..                        ..              \n",
      "  +---------------+                      ..            \n",
      "  | run_diagnosis |                       .            \n",
      "  +---------------+                       .            \n",
      "          *                               .            \n",
      "          *                               .            \n",
      "          *                               .            \n",
      "+-------------------+           +-------------------+  \n",
      "| negative_response |           | positive_response |  \n",
      "+-------------------+           +-------------------+  \n",
      "                  **              **                   \n",
      "                    ***        ***                     \n",
      "                       **    **                        \n",
      "                     +---------+                       \n",
      "                     | __end__ |                       \n",
      "                     +---------+                       \n"
     ]
    }
   ],
   "source": [
    "# Visualize the Workflow Structure\n",
    "# Shows conditional branching for review responses\n",
    "workflow.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5692161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'Food was cold when served, portions were tiny, and the staff seemed disinterested. Not worth the price.',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Performance',\n",
       "  'tone': 'angry',\n",
       "  'urgency': 'medium'},\n",
       " 'response': \"I can sense your frustration with the performance issue you're experiencing, and I'm truly sorry that it's causing you distress. I'm here to help you resolve this problem as efficiently as possible.\\n\\nFirstly, please know that I'm committed to providing you with a solution that meets your needs. I understand that this issue is important to you, and I'll do my best to address it with the urgency it deserves.\\n\\nTo better assist you, could you please provide more details about the performance issue you're encountering? This will enable me to gain a deeper understanding of the problem and work towards a more effective solution.\\n\\nIn the meantime, I'd like to offer some potential troubleshooting steps that may help alleviate the issue. However, if these steps don't resolve the problem, please don't hesitate to let me know, and we'll explore further options together.\\n\\nYour satisfaction is my top priority, and I appreciate your patience and cooperation as we work through this challenge. If you have any questions or concerns, please don't hesitate to reach out to me directly. I'm here to listen and provide support every step of the way.\\n\\nLet's work together to get this issue resolved, and I'm confident that we can find a solution that gets you back up and running smoothly.\"}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the Workflow with Sample Review\n",
    "# Test the review reply workflow for a sample negative review\n",
    "initial_state = {\n",
    "    'review' : 'Food was cold when served, portions were tiny, and the staff seemed disinterested. Not worth the price.'\n",
    "}\n",
    "\n",
    "workflow.invoke(initial_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
